{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868c1e99-5f27-4d24-98e8-3a2e9265535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Spacer, Image as ReportLabImage, Paragraph\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from PIL import Image as PILImage\n",
    "from spire.pdf import PdfDocument\n",
    "from spire.pdf.common import ImageFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cea73d-a3e2-4a5d-ad27-1c1cabdfc918",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_url = 'https://arxiv.org/pdf/1706.03762.pdf'\n",
    "loader = PyPDFLoader(pdf_url)\n",
    "text = str(loader.load())\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5136a1-decb-4c4a-a4d0-9f9fe35f26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "doc = pdf_reader.read_pdf(pdf_url)\n",
    "doc = doc.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae9c7d5-a218-4a86-8e16-c1d658fcd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(doc, 'html.parser')\n",
    "\n",
    "headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'td'])\n",
    "headers_text = [header.get_text(strip=True).strip() for header in headers]\n",
    "headers_text = list(dict.fromkeys(headers_text))\n",
    "\n",
    "pattern = re.compile(r'^\\d+(\\.\\d+)*\\s')\n",
    "\n",
    "numbered_headers = [header for header in headers_text if pattern.match(header)]\n",
    "intro_present = any(re.match(r'^1\\s+Introduction', header, re.IGNORECASE) for header in numbered_headers)\n",
    "\n",
    "if not intro_present:\n",
    "    index_for_intro = next((i for i, header in enumerate(numbered_headers) if header.startswith('2 ')), 0)\n",
    "    numbered_headers.insert(index_for_intro, '1 Introduction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1cce0e-3938-46a7-8e6a-11708d6f5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_pattern = re.compile(r'''\n",
    "    ^                         # Начало строки\n",
    "    (\\d+(\\.\\d+)*)             # Номер раздела или подраздела (например, \"3\", \"3.2\", \"3.2.1\")\n",
    "    (\\s+[A-Za-z].*)           # Пробел и название раздела, начинающееся с буквы\n",
    "    $                         # Конец строки\n",
    "    |                         # ИЛИ\n",
    "    ^\\d+\\s\\d+\\.\\d+\\s          # Начинается с чисел, разделенных пробелами, с точкой между числами\n",
    "    (\\d+\\.\\d+\\s+)*            # Продолжается серией чисел с точками и пробелами\n",
    "    \\d+K?\\.\\d+                # Заканчивается на число с десятичной частью, возможно с \"K\"\n",
    "    (\\s\\d+)*                  # За которым следуют пробелы и числа\n",
    "    $                         # Конец строки\n",
    "''', re.VERBOSE)\n",
    "headers = [header for header in numbered_headers if updated_pattern.match(header)]\n",
    "headers.append(\"References\") if \"References\" in text else \"REFERENCES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9daac1bb-c8b4-47e6-a211-e9a5e78ef172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(pdf_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('arXiv_doc.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    doc = PdfDocument()\n",
    "    doc.LoadFromFile('arXiv_doc.pdf')\n",
    "    \n",
    "images = []\n",
    "\n",
    "for i in range(doc.Pages.Count):\n",
    "    page = doc.Pages.get_Item(i)\n",
    "    for image in page.ExtractImages():\n",
    "        images.append(image)\n",
    "        \n",
    "index = 0\n",
    "\n",
    "for image in images:\n",
    "    imageFileName = r'images\\image_{0}.png'.format(index).format(index)\n",
    "    index += 1\n",
    "    image.Save(imageFileName, ImageFormat.get_Png())\n",
    "    \n",
    "doc.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad41a6e-7f3f-4cc9-9d2f-d413fc1cc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize(text):\n",
    "    inputs_no_trunc = tokenizer(text, max_length=None, return_tensors='pt', truncation=False)\n",
    "    \n",
    "    chunk_start = 0\n",
    "    chunk_end = tokenizer.model_max_length  # == 1024 for Bart\n",
    "    inputs_batch_lst = []\n",
    "    space_token_id = tokenizer.encode(' ', add_special_tokens=False)[0]\n",
    "    \n",
    "    while chunk_start <= len(inputs_no_trunc['input_ids'][0]):\n",
    "        try:\n",
    "            current_chunk = inputs_no_trunc['input_ids'][0][chunk_start:chunk_end].tolist()\n",
    "            end_index = len(current_chunk) - 1 - current_chunk[::-1].index(space_token_id)\n",
    "            chunk_end = chunk_start + end_index\n",
    "        except ValueError:\n",
    "            pass\n",
    "        inputs_batch = inputs_no_trunc['input_ids'][0][chunk_start:chunk_end] # get batch of n tokens\n",
    "        inputs_batch = torch.unsqueeze(inputs_batch, 0)\n",
    "        inputs_batch_lst.append(inputs_batch)\n",
    "        chunk_start = chunk_end + 1\n",
    "        chunk_end = min(chunk_start + tokenizer.model_max_length, len(inputs_no_trunc['input_ids'][0]))\n",
    "    \n",
    "    summary_ids_lst = [model.generate(inputs, num_beams=4, max_length=500, early_stopping=True) for inputs in inputs_batch_lst]\n",
    "                                                                    # тут \n",
    "    summary_batch_lst = []\n",
    "    for summary_id in summary_ids_lst:\n",
    "        summary_batch = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_id]\n",
    "        summary_batch_lst.append(summary_batch[0])\n",
    "    summary_all = '\\n'.join(summary_batch_lst)\n",
    "    return summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441582bf-6eff-4641-8890-20c8a9535ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Background\n",
      "3 Model Architecture\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "3.2.2 Multi-Head Attention\n",
      "3.2.3 Applications of Attention in our Model\n",
      "3.3 Position-wise Feed-Forward Networks\n",
      "3.4 Embeddings and Softmax\n",
      "3.5 Positional Encoding\n",
      "4 Why Self-Attention\n",
      "5 Training\n",
      "5.1 Training Data and Batching\n",
      "5.2 Hardware and Schedule\n",
      "5.3 Optimizer\n",
      "5.4 Regularization\n",
      "6 Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Conclusion\n",
      "References\n"
     ]
    }
   ],
   "source": [
    "patternForBrackets = re.compile(r'\\[\\s*\\d+(?:,\\s*\\d+)*\\s*\\]')\n",
    "\n",
    "pdf_path = \"summary.pdf\"\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "style = styles['Normal']\n",
    "elements = []\n",
    "\n",
    "for header in range(len(headers)-1):\n",
    "    startHeader = headers[header]\n",
    "    endHeader = headers[header + 1]\n",
    "    print(endHeader)\n",
    "    dot_count = startHeader.count('.')\n",
    "    if dot_count == 0:\n",
    "        header_style = styles['Heading2']\n",
    "    elif dot_count != 0:\n",
    "        header_style = styles['Heading5']\n",
    "    \n",
    "    pattern = re.compile(re.escape(startHeader) + \"(.*?)\" + re.escape(endHeader), re.DOTALL)\n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        text_between = match.group(1)\n",
    "        text_without_brackets = patternForBrackets.sub('', text_between)\n",
    "        text_final = text_without_brackets.replace(\"\\\\n\",\"\")\n",
    "        text_final = text_final.replace(\"\\n\",\"\")\n",
    "\n",
    "        summary_text = summerize(text_final)\n",
    "        \n",
    "        elements.append(Paragraph(startHeader, header_style))\n",
    "        elements.append(Paragraph(summary_text, style))\n",
    "        elements.append(Spacer(1, 12))\n",
    "        \n",
    "\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "for img_num in range(len(images)):\n",
    "    image_path = f'images/image_{img_num}.png'\n",
    "    pil_image = PILImage.open(image_path)\n",
    "    real_width, real_height = pil_image.size\n",
    "\n",
    "    dpi = 72  # или используйте реальное DPI изображения, если оно вам известно\n",
    "    width_in_points = real_width / dpi * 10\n",
    "    height_in_points = real_height / dpi * 10\n",
    "\n",
    "    # Убедитесь, что размеры являются числами, а не строками\n",
    "    width_in_points = float(width_in_points)\n",
    "    height_in_points = float(height_in_points)\n",
    "\n",
    "    # Добавление изображения с использованием ReportLab Image\n",
    "    img = ReportLabImage(image_path, width_in_points, height_in_points)\n",
    "    elements.append(img)\n",
    "    \n",
    "    # Добавление заголовка\n",
    "    centered_style = ParagraphStyle(name='CenteredStyle', parent=styles['Normal'], alignment=TA_CENTER)\n",
    "    elements.append(Paragraph(f\"Figure {img_num}\", centered_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "doc.build(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad092cd-f16f-40ee-b21e-01777469942f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
